{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb58794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d56cf550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: Langchain is a framework for building applications with LLMs Langchain provides modular abstractions to combine LLMs with tools like openai and Pinecone.\n",
      "\n",
      "Chunk 2: You can create chains, agents, memory and retrievers.\n",
      "\n",
      "Chunk 3: The Eiffel tower is located in Paris.\n",
      "\n",
      "Chunk 4: France is a popular tourist destination.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SentenceTransformer model\n",
    "model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample text\n",
    "text=\"\"\"\n",
    "Langchain is a framework for building applications with LLMs\n",
    "Langchain provides modular abstractions to combine LLMs with tools like openai and Pinecone.\n",
    "You can create chains, agents, memory and retrievers.\n",
    "The Eiffel tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "#Step1: Split the text into sentences\n",
    "sentences = [sentence.strip() for sentence in text.split('\\n') if sentence]\n",
    "\n",
    "#Step2: Generate embeddings for each sentence\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Step3: Initialize variables for semantic chunking\n",
    "threshold = 0.7  # Similarity threshold\n",
    "chunks = []\n",
    "current_chunk = [sentences[0]]\n",
    "\n",
    "#Step4: Perform semantic chunking based on cosine similarity\n",
    "for i in range(1, len(sentences)):\n",
    "    sim = cosine_similarity([embeddings[i]], [embeddings[i-1]])[0][0]\n",
    "    if sim >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "        \n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "# Append the last chunk\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "# Output the semantic chunks\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}: {chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a808bd",
   "metadata": {},
   "source": [
    "### RAG PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b295f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY loaded: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load your .env file (this populates os.environ automatically)\n",
    "load_dotenv()\n",
    "\n",
    "# Now your previous code works without changes\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "# os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")  # DELETE THIS LINE\n",
    "\n",
    "# Verify it loaded\n",
    "print(\"GROQ_API_KEY loaded:\", bool(os.getenv(\"GROQ_API_KEY\")))  # Should print True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edb097f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58ce03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom Semantic Chunking with Threshold\n",
    "\n",
    "class ThresholdSemanticChunker:\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2', threshold: float = 0.7):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def _call(self, text: str) -> list[str]:\n",
    "        sentences = [sentence.strip() for sentence in text.split('\\n') if sentence]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i]], [embeddings[i-1]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        return chunks\n",
    "\n",
    "    def split_documents(self, docs):\n",
    "        results = []\n",
    "        for doc in docs:\n",
    "            for chunk in self._call(doc.page_content):\n",
    "                results.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7c63326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "sample_text=\"\"\"\n",
    "Langchain is a framework for building applications with LLMs\n",
    "Langchain provides modular abstractions to combine LLMs with tools like openai and Pinecone.\n",
    "You can create chains, agents, memory and retrievers.\n",
    "The Eiffel tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=sample_text, metadata={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa2a5310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Langchain is a framework for building applications with LLMs Langchain provides modular abstractions to combine LLMs with tools like openai and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains, agents, memory and retrievers.'),\n",
       " Document(metadata={}, page_content='The Eiffel tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination.')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = ThresholdSemanticChunker(threshold=0.7)\n",
    "chunks = chunker.split_documents([doc])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa8bb5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x306d72210>, search_kwargs={})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vector Store Integration\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Use proper LangChain embeddings wrapper\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    model_kwargs={'device': 'cpu'}  # Use 'cuda' if GPU available\n",
    ")\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ae933a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=' You are a knowledgeable assistant. Use the following context to answer the question:\\n\\nContext: {context}\\n\\nAnswer the question: {question}\\n\\n')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "\n",
    "prompt_template = \"\"\" You are a knowledgeable assistant. Use the following context to answer the question:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Answer the question: {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5153c489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x306f46190>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x306f45480>, model_name='llama-3.3-70b-versatile', temperature=0.4, model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LLM\n",
    "llm = init_chat_model(model=\"groq:llama-3.3-70b-versatile\", temperature=0.4, api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2e87456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCEL\n",
    "rag_chain = (\n",
    "    RunnableMap(\n",
    "    {\n",
    "        \"context\": RunnableLambda(\n",
    "            lambda x: retriever.invoke(x[\"question\"]),\n",
    "        ),\n",
    "        \"question\": RunnableLambda(lambda x: x[\"question\"]),\n",
    "    }\n",
    ")\n",
    "\n",
    "| prompt\n",
    "| llm\n",
    "| StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09a65894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The Eiffel tower is located in Paris.\n"
     ]
    }
   ],
   "source": [
    "# Example Query\n",
    "query = \"Where is the Eiffel tower located?\"\n",
    "response = rag_chain.invoke({\"question\": query})\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1aa66dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The provided context does not mention the location of the Great Wall of China. The context only discusses the Eiffel Tower, France, and the Langchain framework, but does not provide any information about the Great Wall of China. Therefore, I cannot answer the question based on the given context.\n"
     ]
    }
   ],
   "source": [
    "# Example Query\n",
    "query = \"Where is the Great Wall of China located?\"\n",
    "response = rag_chain.invoke({\"question\": query})\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881886c9",
   "metadata": {},
   "source": [
    "### Semantic Chunker with Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2869196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55ae3b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: Langchain is a framework for building applications with LLMs\n",
      "Langchain provides modular abstractions to combine LLMs with tools like openai and Pinecone. You can create chains, agents, memory and retrievers.\n",
      "\n",
      "Chunk 2: The Eiffel tower is located in Paris. France is a popular tourist destination.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(\"langchain_intro.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    model_kwargs={'device': 'cpu'}  # Use 'cuda' if GPU available\n",
    ")\n",
    "\n",
    "chunker = SemanticChunker(embeddings=embeddings)\n",
    "chunks = chunker.split_documents(docs)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk.page_content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Artificial-Intelligence-Bootcamp",
   "language": "python",
   "name": "artificial-intelligence-bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
